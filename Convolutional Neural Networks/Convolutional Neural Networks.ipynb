{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24cc5e92",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c53a84a",
   "metadata": {},
   "source": [
    "## 1. What are Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b65e38-ed7c-48cb-8e56-ecca26306df8",
   "metadata": {},
   "source": [
    "In deep learning, a convolutional neural network (CNN/ConvNet) is a class of deep neural networks, most commonly \n",
    "applied to analyze visual imagery. Now when we think of a neural network we think about matrix multiplications.A special technique called Convolution is used. Now in mathematics convolution is a mathematical operation on two functions that produces a third function that expresses how the shape of one is modified by the other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8832011",
   "metadata": {},
   "source": [
    "## 2. Why CNNs were introduced when Fully connected ANNs were already there"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492eb97e-5b6f-4548-b0b8-734abc8497b1",
   "metadata": {},
   "source": [
    "CNN is based on a deep learning structure that uses packed hidden layers. CNN is convolutional, which means it performs a convolution operation between different submatrices of the input matrix and selected filters. ANN does not have these specificities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32169e18",
   "metadata": {},
   "source": [
    "## 3. What is meant by the following terms: convolutional layer, pooling layer, padding, stride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6620f32d-0a6f-4322-8a70-0b55b7a65f73",
   "metadata": {},
   "source": [
    "The convolution is a mathematical operation used to extract features from an image. The convolution is defined by an image kernel. The image kernel is nothing more than a small matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa24dafd-f81b-4a0e-938c-4ee550fb2560",
   "metadata": {},
   "source": [
    "A pooling layer is another building block of a CNN. Pooling Its function is to progressively reduce the spatial size of the representation to reduce the network complexity and computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83edfe-e721-4139-8356-39c7588c8a02",
   "metadata": {},
   "source": [
    "Padding preserves the size of the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e178aa-1070-47a6-919b-02e3faf6be17",
   "metadata": {},
   "source": [
    "Stride is the number of pixels shifts over the input matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9efde8",
   "metadata": {},
   "source": [
    "## 4. What would be the size of the output if input is n^2, filter is f^2 and stride is of s "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe576b0-36db-4f74-8409-14d0b6edcc7f",
   "metadata": {},
   "source": [
    "[ {(ùëõ + 2ùëù ‚àí ùëì + 1) / ùë†} + 1] ‚àó [ {(ùëõ + 2ùëù ‚àí ùëì + 1) / ùë†} + 1]., p is the padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2777f3b",
   "metadata": {},
   "source": [
    "## 5. What are pre-trained models and what do you mean by transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4ff79f-e8bc-40e8-9c96-426140965229",
   "metadata": {},
   "source": [
    "Transfer learning means that training won't need to be restarted from scratch for every new task. Training new machine learning models can be resource-intensive, so transfer learning saves both resources and time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0897dc8e-e028-4265-afdf-9aef9796b443",
   "metadata": {},
   "source": [
    "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b20a28",
   "metadata": {},
   "source": [
    "## 6. Discuss CPU vs GPU vs TPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e51df8f-5fec-41c3-86aa-2dc9fe097544",
   "metadata": {},
   "source": [
    "CPU: Central Processing Unit. Manage all the functions of a computer.\n",
    "\n",
    "GPU: Graphical Processing Unit. Enhance the graphical performance of the computer.\n",
    "\n",
    "TPU: Tensor Processing Unit. Custom build ASIC to accelerate TensorFlow projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078190a4",
   "metadata": {},
   "source": [
    "## 7. Perform CNN classification on citrus leaves dataset from tensorflow \n",
    "##     (try to achieve minimum 90% accuracy and above on the test set)\n",
    "##     Can be found using the link: https://www.tensorflow.org/datasets/catalog/citrus_leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c878cd0-df7d-4bf6-b06a-f72ceeba26b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d49598-646a-412d-ae07-294a96c70cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator as IDG\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./ 255,\n",
    "    rotation_range=180,\n",
    "    zoom_range=0.3,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.25)\n",
    "\n",
    "train_gen = data_gen.flow_from_directory('C:\\Users\\Checkout\\Desktop\\Spring 22\\CmpE 257\\Assignments\\HW11\\Citrus Plant Dataset\\Citrus\\Leaves', batch_size=32, subset='training')\n",
    "val_gen = data_gen.flow_from_directory('C:\\Users\\Checkout\\Desktop\\Spring 22\\CmpE 257\\Assignments\\HW11\\Citrus Plant Dataset\\Citrus\\Leaves', batch_size=8, subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d312e3-63e9-4a01-941c-7d8b7e11e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f41c27a-e1a5-4e79-8409-59d9d30842c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=(256, 256, 3),padding='same'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(32, (3,3), activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(5, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90c030-0bfa-448c-ba87-964488b66fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f97e7a-2c2c-416b-b032-5263453371ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy','Precision','Recall']\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=35\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca538e-aaa7-4f55-a1e0-33f2591eb3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the model\n",
    "loss, accuracy, precision, recall = model.evaluate(ds_valid)\n",
    "print(f'Validation loss: {round(loss, 2)}')\n",
    "print(f'Validation accuracy: {round(accuracy, 2)}')\n",
    "print(f'Validation precision: {round(precision, 2)}')\n",
    "print(f'Validation recall score: {round(recall, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eac93e",
   "metadata": {},
   "source": [
    "## 8. Plot the model architecture and explain how did you decide number of layers, filter size and other hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b919b0-9153-4003-85e4-98c0140c87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b15c44-e9e4-4631-986c-a376ce7b3d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b2dc9-395d-47a8-959f-52e69b80fbb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff5fb8b5",
   "metadata": {},
   "source": [
    "## 9. Increase the accuracy of the model in the demo file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3e07d-ea12-4926-8100-1d5ba899011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_X,train_Y), (test_X,test_Y) = fashion_mnist.load_data()\n",
    "print('Training data shape : ', train_X.shape, train_Y.shape)\n",
    "print('Testing data shape : ', test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f20013-6ca1-4fee-8f78-fae6a58d9c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_X.reshape(-1, 28,28, 1)\n",
    "test_X = test_X.reshape(-1, 28,28, 1)\n",
    "\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')\n",
    "train_X = train_X / 255.0\n",
    "test_X = test_X / 255.0\n",
    "\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7562ff-b01c-4bee-b99b-a4980db7df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_label,valid_label = train_test_split(train_X, train_Y_one_hot, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9621a3e5-3c82-4117-ae67-50e3e13d0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 30\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d31e8-0bbc-4436-b338-bd81de5fb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape=(28,28,1), padding = 'same'))\n",
    "fashion_model.add(LeakyReLU(alpha = 0.2))\n",
    "fashion_model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "fashion_model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "fashion_model.add(LeakyReLU(alpha = 0.2))\n",
    "fashion_model.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\n",
    "fashion_model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
    "fashion_model.add(LeakyReLU(alpha = 0.2))                  \n",
    "fashion_model.add(MaxPooling2D(pool_size = (2, 2), padding = 'same'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(128, activation = 'relu'))\n",
    "fashion_model.add(LeakyReLU(alpha = 0.2))                  \n",
    "fashion_model.add(Dense(num_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed39a8-9b3e-4d69-aebe-fc55f79c02ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.compile(loss = tensorflow.keras.losses.categorical_crossentropy, optimizer = tensorflow.keras.optimizers.Adamax(), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0353c15-7ee1-4f7c-93e0-37f1851aee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fashion_train = fashion_model.fit(train_X, train_label, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (valid_X, valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4e6d96-580a-4f68-a9e0-a4066be3ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "test_eval = fashion_model.evaluate(test_X, test_Y_one_hot, verbose = 1)\n",
    "print('Test accuracy:', test_eval[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
