{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3374639",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ad5de",
   "metadata": {},
   "source": [
    "## 1. What is boosting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675057f9-4d0c-4a64-bed3-0ccfe2fa222a",
   "metadata": {},
   "source": [
    "Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. \n",
    "In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate \n",
    "for the weaknesses of its predecessor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e79f428",
   "metadata": {},
   "source": [
    "## 2. Explain the following three models: Adaboost, Gradient boost and XGboost (also discuss their similarities and differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85187d22-c2f3-46fb-a1c0-2544cfe1813b",
   "metadata": {},
   "source": [
    "AdaBoost is an ensemble learning method (also known as “meta-learning”) which was initially created to increase the \n",
    "efficiency of binary classifiers.AdaBoost uses an iterative approach to learn from the mistakes of weak classifiers, and \n",
    "turn them into strong ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe67697d-137c-4381-8d72-bda3cdf96424",
   "metadata": {},
   "source": [
    "Gradient boosting is a machine learning technique used in regression and classification tasks, among others. \n",
    "It gives a prediction model in the form of an ensemble of weak prediction models, which are typically decision trees.\n",
    "When a decision tree is the weak learner, the resulting algorithm is called gradient-boosted trees; it usually outperforms random forest.\n",
    "A gradient-boosted trees model is built in a stage-wise fashion as in other boosting methods, but it generalizes the other methods by \n",
    "allowing optimization of an arbitrary differentiable loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382c1fa5-20aa-48f5-bc6b-a1acdb2e9c26",
   "metadata": {},
   "source": [
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. \n",
    "It implements machine learning algorithms under the Gradient Boosting framework. XGBoost provides a parallel tree boosting \n",
    "(also known as GBDT, GBM) that solve many data science problems in a fast and accurate way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1aae4-7c28-4e63-a03e-faf42ac95644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e75491a",
   "metadata": {},
   "source": [
    "## 3. what is a Dmatrix? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0cfb1-36d8-4c74-88b2-ab311b5d4221",
   "metadata": {},
   "source": [
    "DMatrix object from either a dense matrix, a sparse matrix, or a local file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17aa565-88d2-4a24-9a1f-7511314f9be4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2619fa56",
   "metadata": {},
   "source": [
    "## 4. Load the dataset attached with this HW (wholesale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11316f46-4a5e-4b87-9d3e-9b25f53e4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.read_csv(\"wholesale-data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45c93f",
   "metadata": {},
   "source": [
    "## 5. Change the dataset into a dmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b6b4ac-40a0-4315-ae65-f6ec2691349a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\checkout\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\checkout\\anaconda3\\lib\\site-packages (from xgboost) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\checkout\\anaconda3\\lib\\site-packages (from xgboost) (1.20.3)\n"
     ]
    }
   ],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=pd.DataFrame(data=df[\"Channel\"])\n",
    "!pip install xgboost\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd3d07f-a53a-4ef3-9a8f-db163e33a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 100)\n",
    "xgb_reg = xgboost.XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4da757d2-3659-4c33-aba0-5d45e991a4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xgboost.core.DMatrix at 0x1bbe2a6efd0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = xgboost.DMatrix(data=X, label=y)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50497e93",
   "metadata": {},
   "source": [
    "## 6. What is an imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b38648-afcc-4762-92fc-28ac98072317",
   "metadata": {},
   "source": [
    "Imbalanced data refers to those types of datasets where the target class has an uneven distribution of observations, \n",
    "i.e one class label has a very high number of observations and the other has a very low number of observations. We can better understand it with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b5e2ee",
   "metadata": {},
   "source": [
    "## 6. perform classification with \"channel\" as the target variable and XGBoost as the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba9417f-c311-47ce-b98f-962eb194fc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:43:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Checkout\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Checkout\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train)\n",
    "y_train_pred = xgb_reg.predict(X_train)\n",
    "y_test_pred = xgb_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ecb39ea-8eae-4135-a40f-b4c0909f004a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1,\n",
       "       2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebcde35d-1313-4d20-8207-78bb368fa5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qqplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00002c1f",
   "metadata": {},
   "source": [
    "## 7. Evaluate the model using accuracy, f1 score, AUROC and AUPRC and explain which one is the best evaluation metric for this model and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a5a5d50-cd2c-446b-8b1b-04ca001b98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa880fc3-5896-439b-b8ce-16b3d531361b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_train, y_train_pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e769236d-3243-491c-93c9-0060062a8dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286114221724524"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_test_pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e5d0568-ec7b-48bc-9f55-787b50ca67f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.808991714319057"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auprc = metrics.average_precision_score(y_test, y_test_pred, pos_label=2)\n",
    "auprc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aa57f54-69d4-4753-b90d-e65ec018f739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.97      0.94      0.95        94\n",
      "           2       0.85      0.92      0.89        38\n",
      "\n",
      "    accuracy                           0.93       132\n",
      "   macro avg       0.91      0.93      0.92       132\n",
      "weighted avg       0.93      0.93      0.93       132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75880d25-4534-48f5-ab92-4eca9ab6e694",
   "metadata": {},
   "source": [
    " AUROC gives the best results as the data set is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e69ea4-c3a4-48a5-8c88-4eb643c8347e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
