{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random-Forest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1lpkY8Tr9p1"
      },
      "outputs": [],
      "source": [
        "# importing required libraries\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from random import randrange\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. complete the following function that creates subsample of a dataset with replacement"
      ],
      "metadata": {
        "id": "JJ8RbTeWss-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random subsample from the dataset with replacement\n",
        "def subsample(dataset, ratio): \n",
        "  # WRITE YOUR CODE HERE\n",
        "  # IF NUMBER OF ROWS IN CURRENT DATASET IS N, THE OUTPUT DATASET SHOULD HAVE N*RATIO NUMBER OF ROWS SELECTED RANDOMLY WITH REPLACEMENT FROM THE ORIGINAL DATASET\n",
        "  # INPUT AND OUTPUT DATATYPE SHOULD BE PANDAS DATAFRAME\n",
        "  return # SAMPLED DATASET WITH REPLACEMENT WITH THE SIZE OF GIVEN RATIO"
      ],
      "metadata": {
        "id": "gfywPfDSsR5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. complete the following function that creates subsample of the dataset with feature size reduced as per the given ratio"
      ],
      "metadata": {
        "id": "DLhI-zEEtlyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random selection of n features\n",
        "def subsample2(dataset, ratio):\n",
        "  # WRITE YOUR CODE HERE\n",
        "  # THE OUTPUT DATASET SHOULD HAVE SAME NUMBER OF ROWS AS THE INPUT DATASET\n",
        "  # IF NUMBER OF FEATURES IN THE INPUT DATASET IS N, THEN THE NUMBER OF FEATURES IN THE OUTPUT DATASET SHOULD BE N*ratio\n",
        "  # THE INPUT AND OUTPUT DATATYPE SHOULD BE PANDAS DATAFRAME\n",
        "  return # RETURN 2 ITEMS, 1ST IS THE SELECTED COLUMNS (DATATYPE LIST) AND 2ND IS THE REDUCED DATAFRAME"
      ],
      "metadata": {
        "id": "dOAhJeWJtuzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perform train test split without using sklearn (complete the following function)"
      ],
      "metadata": {
        "id": "AdKEbw1KvGw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting dataset into train and test\n",
        "def split_train_test(dataset, test_size):\n",
        "  # WRITE YOUR CODE HERE\n",
        "  # DATASET IS THE INPUT DATAFRAME\n",
        "  # TEST_SIZE IS THE SIZE OF TESTING SET IN FORM OF FRACTION BETWEEN 0 AND 1\n",
        "  # OUTPUT TWO DATAFRAMES, TRAIN AND TEST DATA\n",
        "  return # train_data, test_data"
      ],
      "metadata": {
        "id": "nrFce8BjvX75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Perform training using random forest algorithm by completing the function below"
      ],
      "metadata": {
        "id": "L3HDWKIav4H_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Algorithm\n",
        "def random_forest_train(train, n_trees, max_depth, sample_size, n_features_ratio):\n",
        "  # WRITE YOUR CODE HERE\n",
        "  # TRAIN IS THE TRAINING DATASET THAT YOU GET FROM THE OUTPUT OF YOUR TRAIN TEST SPLIT\n",
        "  # N_TREES IS NUMBER OF TREES IN THE FOREST\n",
        "  # MAX_DEPTH IS THE MAX_DEPTH OF EACH TREE IN THE FOREST\n",
        "  # SAMPLE SIZE IS THE RATIO OF ROWS TO BE SENT TO EACH TREE (VALUE BETWEEN 0 AND 1)\n",
        "  # N_FEATURES_RATIO IS THE RATIO OF FEATURES TO BE SENT TO EACH TREE\n",
        "  # USE SKLEARN TREES TO SIMLIFY THE EXERCISE\n",
        "  return # A LIST OF [SKLEARN TREE OBJECT, [COLS USED IN THAT TREE]] (SIZE OF OUTPUT LIST WILL BE (N_TREES*2))"
      ],
      "metadata": {
        "id": "iZnkB6aQwPtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Complete the following prediction function of random forest"
      ],
      "metadata": {
        "id": "P4s6TKOpy6T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction with a list of bagged trees\n",
        "def random_forest_predict(test, trees):\n",
        "  # WRITE YOUR CODE HERE\n",
        "  # TEST IS THE TESTING DATASET THAT IS THE OUTPUT OF YOUR TRAIN TEST SPLIT FUNCTION\n",
        "  # TREES ARE THE TRAINED TREES (OUTPUT OF THE RANDOM_FOREST_TRAIN FUNCTION)\n",
        "  # RETURN TWO THINGS, 1 IS FINAL CLASS PREDICTIONS FOR EACH ROW IN TEST DATA, 2 IS THE PREDICTION BY EACH TREE FOR EACH ROW IN THE TEST DATA\n",
        "  return #predictions, all_preds"
      ],
      "metadata": {
        "id": "6OVjGC9VzCra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the dataset\n",
        "dataset = load_iris()\n",
        "df = pd.DataFrame(dataset.data)\n",
        "df[\"target\"] = dataset.target\n",
        "df"
      ],
      "metadata": {
        "id": "a9-kOcMp0E4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting the dataset into train and test\n",
        "train, test = split_train_test(df, 0.3)"
      ],
      "metadata": {
        "id": "Ugg9d5AW0H1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.reset_index(drop = True)\n",
        "test = test.reset_index(drop = True)"
      ],
      "metadata": {
        "id": "HYZN2C1H0IiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees = random_forest_train(train = train, n_trees = 10, max_depth = 3, sample_size = 0.8, n_features_ratio = 0.75)"
      ],
      "metadata": {
        "id": "in6_Bsdg0Kyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees"
      ],
      "metadata": {
        "id": "BML2gpqx0NEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, all_preds = random_forest_predict(test.iloc[:,:-1], trees)"
      ],
      "metadata": {
        "id": "NfPA5I1A0PPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds"
      ],
      "metadata": {
        "id": "5hMfz-Em0RID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "poU_s3Ym0TBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(test.iloc[:,-1], predictions)"
      ],
      "metadata": {
        "id": "MQzNyccX0W18"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}